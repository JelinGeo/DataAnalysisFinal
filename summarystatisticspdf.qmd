---
title: "The Importance of Summary Statistics and Techniques for Creating Them in R"
shorttitle: "Summary Statistics and Techniques in R"
# Set names and affiliations.
# It is nice to specify everyone's orcid, if possible.
# There can be only one corresponding author, but declaring one is optional.
author:
  - name: "Jelin George (Matriculation: 400826617)"
    corresponding: true
    
    email: george.jelin@stud-hs.fresenius.de
    url: 
    affiliations:
      - id: "400826617"
        name: "Hochschule Fresenius - University of Applied Science"
        group: "International Management, M.A."
        department: 
        address: 
        city: 
        region: 
        country: 
        postal-code: 
blank-lines-above-author-note: 2
author-note:
  status-changes: 
    # Example: [Author name] is now at [affiliation].
    affiliation-change:
    # Example: [Author name] is deceased.
    deceased: ~
  # Disclosures condensed to one paragraph, but you can start a field with two line breaks to break them up: \n\nNew Paragraph
  disclosures:
    # Example: This study was registered at X (Identifier Y).
    study-registration: ~
    # Acknowledge and cite data/materials to be shared.
    data-sharing: ~
    # Example: This article is based on data published in [Reference].
    # Example: This article is based on the dissertation completed by [citation].  
    related-report: ~
    # Example: [Author name] has been a paid consultant for Corporation X, which funded this study.
    conflict-of-interest: The authors have no conflicts of interest to disclose.
    # Example: This study was supported by Grant [Grant Number] from [Funding Source].
    financial-support: ~
    # Example: The authors are grateful to [Person] for [Reason].
    gratitude: ~
    # Example. Because the authors are equal contributors, order of authorship was determined by a fair coin toss.
    authorship-agreements: ~
abstract: "This document presents a concise overview of summary statistics and their importance in R. Summary statistics - such as mean, median, standard deviation, and frequency counts - capture the key features of a dataset, enabling quick exploration and interpretation. R provides powerful functions and visualization tools to efficiently compute and present these statistics, making them essential for simplifying data, identifying patterns, and supporting informed analysis and decision-making." 
keywords: [summary statistics, R programming, data analysis, data visualisation, data summarisation]
# If true, tables and figures are mingled with the text instead of listed at the end of the document.
impact-statement: ~
floatsintext: true
# Numbered lines (.pdf and .docx only)
numbered-lines: false
# File with references
bibliography: bibliography.bib
csl: apa.csl
# Suppress title page
suppress-title-page: false
# Link citations to references
link-citations: true
# Masks references that appear in the masked-citations list
mask: false
masked-citations:
# If true, adds today's date below author affiliations. If text, can be any value.
# This is not standard APA format, but it is convenient.
# Works with docx, html, and typst. 
draft-date: false
# Language options. See https://quarto.org/docs/authoring/language.html
lang: en-US
language:
  citation-last-author-separator: "and"
  citation-masked-author: "Masked Citation"
  citation-masked-date: "n.d."
  citation-masked-title: "Masked Title"
  email: "Email"
  title-block-author-note: "Author Note"
  title-block-correspondence-note: "Correspondence concerning this article should be addressed to"
  title-block-role-introduction: "Author roles were classified using the Contributor Role Taxonomy (CRediT; [credit.niso.org](https://credit.niso.org)) as follows:"
  title-impact-statement: "Impact Statement"
  references-meta-analysis: "References marked with an asterisk indicate studies included in the meta-analysis."
format:
  apaquarto-html: 
    toc: true
    theme: cosmo
    echo: true
    css: styles.css
  apaquarto-typst: 
    keep-typ: true
    list-of-figures: false
    list-of-tables: false
    toc: true
    papersize: "us-letter"
  apaquarto-pdf:
    # Can be jou (journal), man (manuscript), stu (student), or doc (document)
    toc: true
    documentmode: man
    keep-tex: true
echo: true
---

Summary statistics are concise numerical measures that capture the essential characteristics of a dataset. They serve as foundational tools in data analysis, providing concise descriptions of large datasets. They help analysts and researchers understand the central tendencies, variability, and overall distribution of data, making complex datasets interpretable and actionable. Without summary statistics, raw data would be overwhelming and difficult to interpret, making it challenging to draw meaningful conclusions or communicate findings effectively.

In R, summary statistics are foundational for data analysis, enabling users to efficiently condense complex data into interpretable values like the mean, median, mode, standard deviation, and quantiles. These statistics provide a snapshot of the data, facilitating initial exploration, quality checks, and communication of results.

In this document, we will:

-   Define summary statistics and their importance

-   Explore key measures and techniques

-   Demonstrate practical application with code

-   Discuss best practices and common pitfalls

\newpage

<br>

# What is Summary Statistics?

Summary statistics are numerical values that describe the main features of a dataset, such as its center and spread. They simplify complex data into easily interpretable numbers, offering quick insights into trends and variability, and serve as a foundation for further analysis. These statistics provide a snapshot of the data, facilitating initial exploration, quality checks, and communication of results.

R offers a rich ecosystem of functions and packages - such as summary(), dplyr::summarise(), and visualization tools like histograms and boxplots - that streamline the computation and presentation of summary statistics for both numeric and categorical data. Their importance lies in simplifying large datasets, revealing patterns and outliers, and laying the groundwork for deeper statistical analyses and informed decision-making.

As the first and often most critical step in any analytical workflow, summary statistics in R empower analysts and researchers to understand, compare, and communicate data-driven insights with clarity and precision.

Summary statistics can be typically divided into:

1.  **Descriptive statistics**: Summarize the main features of a dataset (e.g., mean, median, mode). *This will be our focus here.*

2.  **Inferential statistics**: Make predictions or inferences about a population based on a sample (not the focus here).

I would like to highlight a book, *Making sense of statistics: A conceptual overview*, [@oh2023making] which offers a clear and accessible introduction to key statistical concepts for beginners. The book focuses on building conceptual understanding of both descriptive and inferential statistics, using simple explanations, practical examples, and step-by-step guidance. It is designed to help students from any discipline gain confidence in applying statistics to research and interpreting data effectively.

Watch this [**tutorial video**](https://www.youtube.com/watch?v=yoPGwvUzjgQ) on descriptive statistics in R to get you started.

\newpage

<br>

# Key Measures in Summary Statistics

## Measures of Central Tendency

Central tendency measures indicate where most values in a dataset fall.

-   **Mean**: The arithmetic average. Add up all the values, then divide by how many there are to get the average of all the numbers.

-   **Median**: The middle value when data is ordered. If there’s an even number, it’s the average of the two middle numbers.

-   **Mode**: The most frequently occurring value.

```{r}
# Example in R

#| echo: true
#| label: mean-median-mode
data <- c(2, 4, 4, 4, 5, 7, 9)
mean(data)   # Arithmetic mean
median(data) # Median
Mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}
Mode(data)   # Mode

```

## Measures of Dispersion

Dispersion measures describe the spread of data.

![Distributions With Different Dispersion](Dispersionimage.png){#fig-dispersion apa-note="Comparison of two distributions with different dispersion. The taller, narrower curve has less dispersion (lower variance), while the shorter, wider curve has more dispersion (higher variance)." width="60%"}

-   **Range**: Difference between max and min values.

-   **Variance**: Average squared deviation from the mean.

-   **Standard Deviation**: Square root of variance.

-   **Interquartile Range (IQR)**: Range between the 25th and 75th percentiles.

-   **Coefficient of Variation**: Standard deviation divided by the mean.

```{r}
range(data)
var(data)
sd(data)
IQR(data)
sd(data)/mean(data) # Coefficient of Variation

```

## Measures of Shape and Distribution

Describe the overall pattern and characteristics of how data values are distributed within a dataset.

-   **Skewness**: Measures asymmetry of the distribution.
-   **Kurtosis**: Measures "tailedness" or peakedness of the distribution.

```{r}
library(e1071)
skewness(data)
kurtosis(data) 
```

**Visualization tools to help understand distribution of data better.**

-   **Histogram**: It displays how data values are distributed across different intervals in patterns like bell-shaped (normal), J-shaped, or skewed distributions, as well as spot outliers and the overall spread of the data.

```{r}
# This histogram shows the distribution in the example we set previously.

#| label: fig-histogram
#| fig-cap: "Histogram of the data"
hist(data, main="Figure1.Histogram of Data", col = "grey")

```

As seen above, the distribution is centered around 4.

-   **Boxplot**: A graphical tool that visually summarizes the distribution, central tendency, spread, and skewness of numerical data using the five-number summary: minimum, first quartile (Q1), median, third quartile (Q3), and maximum.

```{r}
boxplot(data, main="Figure2.Boxplot of Data", col="grey")
```

## Handling Missing Data

Missing data can bias summary statistics if not handled properly.

Types of missing data: MCAR (Missing Completely at Random), MAR (Missing at Random), MNAR (Missing Not at Random).

Techniques: Omit missing values, impute with mean/median/mode, or use advanced imputation.

```{r}
data_with_na <- c(2, 4, NA, 4, 5, NA, 9)
mean(data_with_na, na.rm=TRUE) # Ignore NAs

```

<br>

## Frequency and Cross-Tabulation Techniques

**Frequency table**: A tool used to organize and display how often each value or category occurs in a dataset. It typically consists of two or more columns: one listing all possible values or categories, and another showing the frequency (count) of each making it easier to see which values are common or rare, summarize large sets of data, and identify patterns.

-   **Relative frequency**: Proportion of each category.
-   **Cumulative frequency**: Running total of frequencies.

```{r}
# To create a frequency table 
category <- c('A', 'B', 'A', 'C', 'B', 'A')
table(category)


# To calculate the proportion of each unique value in the vector category
prop.table(table(category)) |>
round(digits = 2)

```

```{r}
# To calculate the total of frequencies
category <- c('A', 'B', 'A', 'C', 'B', 'A')
cumulative_freq <- cumsum(table(category))
cumulative_freq

```

**Cross-tabulations** (contingency tables): Used in statistics to examine and summarise the relationship between two or more categorical variables. In a cross-tabulation, one variable's categories are arranged in the rows and another variable's categories in the columns, with each cell showing the frequency (count) of observations that fall into the corresponding combination of categories.

```{r}
gender <- c('M', 'F', 'F', 'M', 'F', 'M')
table(category, gender)

```

Row/column proportions: Use prop.table() with margin argument.

```{r}
gender <- c('M', 'F', 'F', 'M', 'F', 'M')
prop.table(table(category, gender)) |>
round(digits = 3)
```

\newpage

<br>

# Summarizing Data Frames

We can create comprehensive summaries for entire datasets by summarizing data frames. This involves generating clear overviews of each variable and its values, typically by calculating summary statistics such as the mean, median, minimum, maximum, standard deviation, and counts. These summaries help reveal the structure, trends, and important features of the data.

Let’s explore a basic example using the summary() function.

```{r}
# Install skimr if not already installed
# install.packages("skimr")

#| echo: true
#| tbl-cap: "Data Structure with glimpse"
#| tbl-format: tblr
#| layout: autofill

library(skimr)
df <- data.frame(
  Age = c(21, 22, 22, 23, 24, 25, 25),
  Gender = c('F', 'M', 'M','F', 'F', 'M', 'M'),
  Score = c(85, 90, 88, 95, 85, 88, 80)
)

knitr::kable(summary(df), format = "pipe")  # Forces table formatting

```

<br>

We can use the above dplyr::glimpse(df) for a quick structure overview, or summary(df) for base R summaries, but skimr gives the most detailed tidy summary. You can further explore [skimr](https://docs.ropensci.org/skimr/) here.

Furthermore, read [Modern Statistics with R](https://modernstatisticswithr.com/index.html) to understand essential tools and techniques in contemporary statistical data analysis, using the R programming language. The book features numerous examples and over 200 exercises with worked solutions. The online version is freely available and regularly updated, with downloadable datasets for hands-on learning

The YouTube videos referenced here may assist in understanding the code chunks presented above. [@walker2023gtsummary] [@dre2024gentle]

\newpage

<br>

# Practical Application

Let us begin with a few fun exercises to understand how to read data and apply summary statistics functions using the **Star Wars** dataset.

Before we get started, we must install essential packages that might be needed later.

```{r}
if (!require(pacman)) install.packages("pacman")
pacman::p_load(tidyverse)
```

```{r}
#| label: setup
#| include: false
library(conflicted)
library(tidyverse)
library(flextable)
library(ftExtra)
library(knitr)
library("htmltools")
library("ggplot2")
library(dplyr)
library(DT)
library(kableExtra)
conflicts_prefer(dplyr::filter, .quiet = TRUE)
conflicts_prefer(flextable::separate_header, .quiet = TRUE)

```

Next, load the Star Wars dataset available online in the dylyr package. [@dplyr2023]

```{r}
library(dplyr)
data(starwars)
```

Let's now streamline the dataset to include only the essential variables before applying the summary functions.

```{r}
#| echo: true
#| tbl-cap: "Table 1. Star Wars Data"
#| tbl-format: tblr
#| colspec: "X X X X X X X X X X"  # 10 columns, all auto-fit

library(knitr)
library(kableExtra)
kable(head(starwars, 10), format = "latex", booktabs = TRUE) %>%
  kable_styling(latex_options = "striped", full_width = FALSE)

```

```{r}
# Mean height
starwars %>% summarise(mean_height = mean(height, na.rm = TRUE))
```

```{r}
# Median height
starwars %>% summarise(median_height = median(height, na.rm = TRUE))
```

```{r}
# Mode height
get_mode <- function(x) {
  # Get unique values in x
  ux <- unique(x)                              
  # Find the value with the highest frequency
  ux[which.max(tabulate(match(x, ux)))]        
}

starwars %>% summarise(mode_height = get_mode(height[!is.na(height)]))

```

Now, let's apply various summary functions.

```{r}
# Select relevant variables
starwars_selected <- starwars %>% select(height, mass, gender, birth_year, species)

# Base R summary for numeric variables
summary(starwars_selected %>% select(height, mass))

# Frequency table for gender
table(starwars_selected$gender)

# Proportion table for gender
prop.table(table(starwars_selected$gender))

# Comprehensive summary using skimr
skim(starwars_selected)
```

<br>

Let's look at a visual pattern of the height of different characters in Star Wars.

```{r}
library(dplyr)
library(ggplot2)

starwars %>%
  ggplot(aes(x = height)) +
  geom_histogram(binwidth = 8, fill = "navy", color = "blue") +
  labs(
    title = "Figure3.Histogram of Height of Characters in Star Wars",
    x = "Height (cm)",
    y = "Count"
  ) +
  theme_minimal()
```

Now, we filter the species to get visual pattern of the height of different *human* characters in Star Wars.

```{r}
starwars %>%
  filter(species == "Human") %>%
  ggplot(aes(x = height)) +
  geom_histogram(binwidth = 8, fill = "navy", color = "blue") +
  labs(
    title = "Figure4.Histogram of Height of Human Characters in Star Wars",
    x = "Height (cm)",
    y = "Count"
  ) +
  theme_minimal()
```

Furthermore, this YouTube video [Return of the Star Wars dataset](https://www.youtube.com/watch?v=4vSfbz9YMa0) might be an interesting watch to understanding the dataset better.

\newpage

<br>

# Limitations

Summary statistics are essential for providing a quick and accessible overview of a dataset, but they have several important limitations. In the book Naked Statistics, the author Charles Wheelan highlights key limitations of statistics, warning that statistical measures can be easily misapplied, misinterpreted, or manipulated to mislead people. He explains that while statistics help summarize complex data, this simplification can lead to information loss and oversights, especially when descriptive statistics are mistaken for complete truth. He emphasizes that statistics are only as reliable as the data and methods behind them, and that issues like bias, poor sampling, or careless analysis can produce misleading or false conclusions. [@wheelan2013naked]

Let's look at some of the limitations in detail:

-   No Causality or Explanation: Summary statistics describe what is present in the data but cannot explain why patterns exist or establish causal relationships. For example, knowing the average test score does not reveal the factors that influenced those scores.

-   Limited to the Sample: These statistics only summarize the data actually measured and cannot be generalized to a broader population without further inferential analysis. They do not account for sampling variability or external validity.

-   No Predictive Power: Summary statistics cannot be used to make predictions about future observations or unmeasured data; they are purely descriptive.

-   Loss of Detail and Nuance: By condensing complex data into single values (like the mean or median), summary statistics can obscure important patterns, subgroups, or variability within the data. For instance, two datasets with the same mean can have very different distributions.

-   Potential for Misleading Conclusions: Relying solely on summary statistics can mask underlying issues such as data bias, or important subgroup differences, leading to incomplete interpretations.

-   No Insight into Relationships: Summary statistics typically focus on individual variables and do not reveal relationships or associations between multiple variables.

In summary, while summary statistics are valuable for initial data exploration, they should be complemented with more detailed analyses and visualizations to avoid oversimplification and misinterpretation of the data.

Other sources: [@wienclaw2009misuse]

\newpage

<br>

# Future Direction

The future direction of summary statistics is being shaped by advances in data complexity, computational power, and the integration of artificial intelligence.Several key trends and directions can be identified:

-   **Integration with Advanced Computational Methods**: As datasets grow larger and more complex, summary statistics will increasingly be complemented by computationally intensive methods such as bootstrapping, simulation-based inference, and machine learning. These approaches allow for more robust and nuanced summaries, especially in high-dimensional or unstructured data settings. [@oscgarden2023bootstrapping]

-   **AI-Driven and Automated Summarization**: Artificial intelligence, including machine learning and natural language processing, is transforming how summary statistics are generated and interpreted. AI-driven summarization tools can quickly distill massive and complex datasets into actionable insights, improving efficiency, accessibility, and consistency. Future developments are expected to include real-time, personalized, and multimodal summarization, making summary statistics more dynamic and tailored to user needs. [@datatas2025future]

-   **Enhanced Visualization and Exploratory Data Analysis**: The role of visualization in summary statistics will continue to grow, leveraging advances in computer graphics and interactive tools. This enables more intuitive and exploratory ways to understand data distributions, trends, and anomalies, moving beyond traditional tables and static plots. [@potter2010visualizing]

-   **Addressing Big Data and Complex Structures**: Summary statistics will need to adapt to the challenges of big data, including handling massive volumes, varied data types, and complex dependencies (such as networks or time-evolving data). This will require new conceptual frameworks and algorithms capable of summarizing information efficiently at scale.[@fan2014challenges]

-   **Ongoing Methodological Innovation**: The field will continue to see progress in robust inference, regularization, causal inference, and adaptive decision analysis, all of which will influence how summary statistics are computed and applied in practice. [@gelman2024stat50]

In summary, the future of summary statistics lies in their evolution from simple descriptive tools to components of sophisticated, automated, and interactive analytical systems. They will play a foundational role in making sense of big, complex, and heterogeneous data, driven by advances in computation, AI, and interdisciplinary collaboration.

\newpage

<br>

# Conclusion

Summary statistics are fundamental to any data analysis process, serving as the essential first step in understanding and interpreting datasets. In R, summary statistics provide a concise overview of data distributions, central tendencies, and variability, enabling analysts to quickly assess data quality, detect anomalies, and guide subsequent analytical decisions. The flexibility and power of R-through core functions like summary(), mean(), sd(), and packages such as dplyr, to efficiently compute and customize statistical summaries for both ungrouped and grouped data.

According to [@lane2013descriptive], using R’s tools to automate calculations of summary statistics-such as mean, median, standard deviation, range, and percentiles-enables users to efficiently produce both overall and group-wise summaries. This not only streamlines exploratory data analysis but also establishes a strong basis for advanced statistical modeling and hypothesis testing. As Lane emphasizes, mastering summary statistics in R allows analysts to extract meaningful insights, make better decisions, and clearly communicate results across various fields of research and business analytics.

\newpage

<br>

# References

<!-- References will auto-populate in the refs div below -->

::: {#refs}
:::

\newpage

<br>

# Affadative

I hereby affirm that this submitted paper was authored unaided and solely by me. Additionally, no other sources than those in the reference list were used. Parts of this paper, including tables and figures, that have been taken either verbatim or analogously from other works have in each case been properly cited with regard to their origin and authorship. This paper either in parts or in its entirety, be it in the same or similar form, has not been submitted to any other examination board and has not been published.

I acknowledge that the university may use plagiarism detection software to check my thesis. I agree to cooperate with any investigation of suspected plagiarism and to provide any additional information or evidence requested by the university.

Checklist:

-   [x] The handout contains 3-5 pages of text.
-   [x] The submission contains the Quarto file of the handout.
-   [x] The submission contains the Quarto file of the presentation.
-   [x] The submission contains the HTML file of the handout.
-   [x] The submission contains the HTML file of the presentation.
-   [x] The submission contains the PDF file of the handout.
-   [x] The submission contains the PDF file of the presentation.
-   [ ] The title page of the presentation and the handout contain personal details (name, email, matriculation number).
-   [x] The handout contains a abstract.
-   [x] The presentation and the handout contain a bibliography, created using BibTeX with APA citation style.
-   [x] Either the handout or the presentation contains R code that proof the expertise in coding.
-   [x] The handout includes an introduction to guide the reader and a conclusion summarizing the work and discussing potential further investigations and readings, respectively.
-   [x] All significant resources used in the report and R code development.
-   [x] The filled out Affidavit.
-   [ ] A concise description of the successful use of Git and GitHub, as detailed here: <https://github.com/hubchev/make_a_pull_request>.
-   [ ] The link to the presentation and the handout published on GitHub.

Jelin George, 28May2025, Cologne
